# GPTalk

> A lightweight, pluggable LLM gateway and orchestration framework built on **Spring AI**.
> Designed for real-world applications: **multi-provider**, **RAG-ready**, **rate-limited**, **observable**, and **production-ready**.

## ‚ù§Ô∏è Why GPTalk?

"LangChain is for Python. GPTalk is for Java.
And it speaks Spring natively."


## üåü Overview

**GPTalk** is an open-source LLM (Large Language Model) gateway and orchestration framework built for Java developers. It is powered by [Spring AI](https://docs.spring.io/spring-ai/) and follows the Spring Boot philosophy: convention over configuration, modularity, and production readiness.

Whether you're building a chatbot, integrating RAG (Retrieval-Augmented Generation), or managing multi-provider LLM traffic, GPTalk provides a robust foundation with support for observability, token tracking, rate-limiting, and more.


## üîß Features

| Feature                   | Description                                                                      |
| ------------------------- | -------------------------------------------------------------------------------- |
| ‚úÖ Multi-LLM Provider      | Supports OpenAI, Azure OpenAI, Anthropic Claude, Alibaba Qwen, Baidu ERNIE, etc. |
| ‚úÖ OpenAI-Compatible API   | Acts as a drop-in replacement for OpenAI-style APIs                              |
| ‚úÖ RAG-Ready               | Provides utilities for document splitting, embedding, and context injection      |
| ‚úÖ Rate Limiting           | Token/request-based rate limiting per user/token/key                             |
| ‚úÖ Observability           | Prometheus metrics, OpenTelemetry tracing, logging, and audit hooks              |
| ‚úÖ Extensible Architecture | Easily add new providers, modify logging/storage/metrics mechanisms              |
| ‚úÖ Spring Boot Native      | Supports auto-configuration, WebFlux, and cloud-native patterns                  |


## üöÄ Getting Started

### Prerequisites

* Java 17+
* Spring Boot 3.2+
* Maven or Gradle

### Example (Spring Boot)

```java
@RestController
@RequiredArgsConstructor
public class ChatController {

    private final ChatClient chatClient;

    @PostMapping("/chat")
    public String chat(@RequestBody String prompt) {
        ChatResponse response = chatClient.call(prompt);
        return response.getResult();
    }
}
```

Configuration example:

```yaml
spring:
  ai:
    openai:
      api-key: your-api-key
      chat:
        options:
          model: gpt-4
```

More examples can be found in the `examples/` folder.

---

## üìÜ Module Structure

```bash
gptalk/
‚îú‚îÄ‚îÄ gptalk-core           # Core abstractions and interfaces
‚îú‚îÄ‚îÄ gptalk-provider       # LLM provider implementation
‚îú‚îÄ‚îÄ gptalk-metrics        # Prometheus / OpenTelemetry instrumentation
‚îú‚îÄ‚îÄ gptalk-rag            # Document splitting, vector store, RAG pipeline
‚îú‚îÄ‚îÄ gptalk-rate-limit     # Token/request-based rate limiter
‚îú‚îÄ‚îÄ gptalk-gateway        # OpenAI-compatible gateway with Spring Cloud Gateway
‚îú‚îÄ‚îÄ gptalk-logging        # Logging, audit, and request tracing
‚îî‚îÄ‚îÄ examples/             # Ready-to-run demos for various providers
```

---

## üìä Observability

GPTalk provides built-in support for:

* **Prometheus**: export metrics for requests, token usage, latency
* **OpenTelemetry**: traces for each LLM call
* **Custom Logging Hooks**: store chat logs in your database or external systems

---

## ‚õîÔ∏è Rate Limiting & Usage Tracking

GPTalk supports:

* Token-based rate limits (per user/API key)
* Redis-based usage counters
* Configurable thresholds for different models
* Usage logs for audit and billing purposes

---

## üß† RAG Support

The `gptalk-rag` module supports:

* Text splitting (recursive, sentence-based)
* Embedding generation (OpenAI, HuggingFace, etc.)
* Vector store integration (Weaviate, Pinecone, FAISS)
* Context injection into prompts

---

## üåê REST API Gateway

`gptalk-gateway` provides an OpenAI-compatible API layer:

* `POST /v1/chat/completions`
* `POST /v1/completions`
* `POST /v1/embeddings`

Supports routing to different models/providers based on request content.


## üéØ Roadmap

* [ ] OpenAI-compatible API proxy
* [ ] RAG module (document -> vector -> context)
* [ ] Token-based rate limiting
* [ ] Prometheus/OpenTelemetry integration
* [ ] Function Calling & Tool Use
* [ ] Web-based dashboard for usage stats
* [ ] SDK clients (Java, Python)

## ‚ù§Ô∏è Join Us

We welcome contributions from the community! If you're interested in:

* Adding support for more LLMs
* Improving the RAG components
* Enhancing the metrics or rate limiter
* Building a dashboard

Feel free to open issues or submit pull requests.

* GitHub: [https://github.com/chat-gptalk/GPTalk](https://github.com/chat-gptalk/GPTalk)
* Docs: [https://gptalk.chat/docs](https://gptalk.chat/docs)
* License: Apache License 2.0
